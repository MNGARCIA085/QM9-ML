{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62711c75-bf45-42ac-b8dd-25760043768d",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: darkblue;\">Results</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aec0de",
   "metadata": {},
   "source": [
    "### ðŸ“‘ <font color='blue'> Table of Contents </font>\n",
    "1. [Introduction](#1)\n",
    "2. [Setup](#2)\n",
    "3. [Helper Functions](#3)\n",
    "4. [Results](#4) <br>\n",
    "    4.1. [Model summary and configuration](#4.1) <br>\n",
    "    4.2. [Validation performance](#4.2) <br>\n",
    "    4.3. [Test performance](#4.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659c5b4",
   "metadata": {},
   "source": [
    "## <a id=\"1\" style=\"color: darkred; text-decoration: none;\">1. Introduction</a>\n",
    "\n",
    "This notebook presents the final results of a model developed to predict the dipole moment of molecules from the QM9 dataset.\n",
    "\n",
    "Here I summarize the final model, its evaluation metrics on the test set, and the main lessons learned throughout the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d0d74",
   "metadata": {},
   "source": [
    "## <a id=\"2\" style=\"color: darkred; text-decoration: none;\">2. Setup </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30545c93-4496-4c06-8756-b5dc750700ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\")) # to be able to import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "699079b6-a227-49a6-a1e0-e8c674d11011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.logging import select_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4883448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME=\"qm9\" # later from conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9684656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow tracking URI\n",
    "mlflow_path = Path().resolve().parent / \"mlflow.db\"\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{mlflow_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd1739",
   "metadata": {},
   "source": [
    "## <a id=\"3\" style=\"color: darkred; text-decoration: none;\">3. Helper Functions </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dee2a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_id_by_name(name):\n",
    "    \"\"\"get exp. id by name\"\"\"\n",
    "    exp = client.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "        raise ValueError(f\"Experiment '{name}' not found.\")\n",
    "    return exp.experiment_id\n",
    "\n",
    "\n",
    "def get_run_data(run_id):\n",
    "    \"\"\"get data from a specific run\"\"\"\n",
    "    client = MlflowClient()\n",
    "    run = client.get_run(run_id)\n",
    "\n",
    "    data = {\n",
    "        \"info\": run.info,\n",
    "        \"params\": run.data.params,\n",
    "        \"metrics\": run.data.metrics,\n",
    "        \"tags\": run.data.tags,\n",
    "        \"artifacts\": {}\n",
    "    }\n",
    "\n",
    "    # download artifacts\n",
    "    for a in client.list_artifacts(run_id):\n",
    "        local_path = client.download_artifacts(run_id, a.path)\n",
    "        data[\"artifacts\"][a.path] = local_path\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# experiment \"test_evaluation\" contains the test results of the previously selected best model\n",
    "# according to val results\n",
    "def get_best(experiment_id, run_name='test_evaluation'):\n",
    "    \"\"\"get data from my best experiment\"\"\"\n",
    "    df = mlflow.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=(\n",
    "            f\"attributes.run_name = '{run_name}' \"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Keep only the best (lowest) test_mse\n",
    "    df = df.sort_values(\"metrics.test_mse\", ascending=True)\n",
    "    best_run = df.iloc[0]\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"run_id\": best_run[\"run_id\"],\n",
    "        \"tuning_run_id\": best_run[\"tags.tuning_run_id\"],\n",
    "        \"metrics\" : {\n",
    "            \"mse\": best_run['metrics.test_mse'],\n",
    "            \"rmse\": best_run['metrics.test_rmse'],\n",
    "            \"mae\": best_run['metrics.test_mae'],\n",
    "            \"r2\": best_run['metrics.test_r2'],\n",
    "            \"ev\": best_run['metrics.test_ev'],\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def get_all_data(exp_name):\n",
    "    exp_id = get_experiment_id_by_name(exp_name)\n",
    "    best_data = get_best(exp_id)\n",
    "    tuning_data = get_run_data(best_data['tuning_run_id'])\n",
    "    return {\n",
    "        \"model_type\": tuning_data[\"tags\"][\"model_type\"],\n",
    "        \"test_metrics\": best_data[\"metrics\"],\n",
    "        \"val_metrics\": tuning_data[\"metrics\"],\n",
    "        \"params\": tuning_data[\"params\"],\n",
    "        # artifacts, loss curve\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7684d1b",
   "metadata": {},
   "source": [
    "## <a id=\"4\" style=\"color: darkred; text-decoration: none;\">4. Results </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d11f8810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3bb042a1344611ba3014ab33c58a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c164aa060707470680b1ef323c267ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get data\n",
    "data = get_all_data(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a576424",
   "metadata": {},
   "source": [
    "### <a id=\"4.1\" style=\"color: darkorange; text-decoration: none;\">4.1. Model summary and configuration </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e5a51c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>schnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type\n",
       "0     schnet"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val_ratio</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subset</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.0015625918075966609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hidden_channels</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_filters</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_interactions</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          parameter                  value\n",
       "0         val_ratio                    0.2\n",
       "1            subset                   6000\n",
       "2            target                      0\n",
       "3        batch_size                     16\n",
       "4                lr  0.0015625918075966609\n",
       "5   hidden_channels                    128\n",
       "6       num_filters                    128\n",
       "7  num_interactions                      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_model = pd.DataFrame([{'model_type': data['model_type']}])\n",
    "\n",
    "df_params = pd.DataFrame(\n",
    "    [{k: v for k, v in data['params'].items()}]\n",
    ").T.reset_index()\n",
    "df_params.columns = [\"parameter\", \"value\"]\n",
    "\n",
    "display(df_model)\n",
    "display(df_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32799e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .... ad entire model config and epochs...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed33e1",
   "metadata": {},
   "source": [
    "### <a id=\"4.2\" style=\"color: darkorange; text-decoration: none;\">4.2. Validation performance </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc03dcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val_mse</td>\n",
       "      <td>0.120330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val_rmse</td>\n",
       "      <td>0.346886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val_mae</td>\n",
       "      <td>0.206557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val_r2</td>\n",
       "      <td>0.951106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val_ev</td>\n",
       "      <td>0.951205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  validation_metric     value\n",
       "0           val_mse  0.120330\n",
       "1          val_rmse  0.346886\n",
       "2           val_mae  0.206557\n",
       "3            val_r2  0.951106\n",
       "4            val_ev  0.951205"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.DataFrame(\n",
    "    [{k: v for k, v in data['val_metrics'].items()}]\n",
    ").T.reset_index()\n",
    "df_val.columns = [\"validation_metric\", \"value\"]\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fafae",
   "metadata": {},
   "source": [
    "### <a id=\"4.3\" style=\"color: darkorange; text-decoration: none;\">4.3. Test Performance </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7341d7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.265931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.515685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mae</td>\n",
       "      <td>0.385589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.693977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ev</td>\n",
       "      <td>0.736624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_metric     value\n",
       "0         mse  0.265931\n",
       "1        rmse  0.515685\n",
       "2         mae  0.385589\n",
       "3          r2  0.693977\n",
       "4          ev  0.736624"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(\n",
    "    [{k: v for k, v in data['test_metrics'].items()}]\n",
    ").T.reset_index()\n",
    "df_test.columns = [\"test_metric\", \"value\"]\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfaeba5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## <a id=\"5\" style=\"color: darkred; text-decoration: none;\">5. Analysis & Conclusion </a>\n",
    "\n",
    "\n",
    "\n",
    "maybe separate............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d057f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad5522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37365b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e268660-7069-4fc0-9d5c-0e10ea070562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
